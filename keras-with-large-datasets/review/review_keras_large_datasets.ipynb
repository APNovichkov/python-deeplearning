{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of using Keras with Large Datasets and Generators\n",
    "\n",
    "- When working with large datasets, the standard approach that we have used before will not work. \n",
    "- This is because when we do model.fit(x,y,...), keras adds that into the physical memory, and if the data is big enough, it can ran out of it, and crash the computer.\n",
    "\n",
    "**This is what Generators are used for**, so let's start by going over what they are!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Function\n",
    "**Def:** This is a type of function in Python, which returns a lazy iterator(lazy evaluation), which uses a call-by-need evaluation strategy, reducing the amount of memory used to run a program.  \n",
    "  \n",
    "A very common use case for generator functions is when reading a huge txt file, which is going to be our use case for it. Here is an example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# lines in file: 892\n"
     ]
    }
   ],
   "source": [
    "def generator_function(file):\n",
    "    for row in open(file, 'r'):\n",
    "        yield row\n",
    "    \n",
    "sum = 0\n",
    "for row in generator_function('titanic.csv'):\n",
    "    sum += 1\n",
    "    \n",
    "print(f'# lines in file: {sum}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference, is we are not returning a specific value from the function, we are using the **yield** keyword, which returns a **lazy iterator**. \n",
    "\n",
    "#### Here is another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "gen = (i for i in range(0,10))\n",
    "\n",
    "print(next(gen))\n",
    "print(next(gen))\n",
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Generators with Keras\n",
    "- This will come in handy, again, when we want to work with a very large dataset, which is usually images, but could be text as well.\n",
    "- The main difference is that we are going to use the **model.fit_generate()** function instead of just **model.fit()**, and pass our data in as a generator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(df, batch_size, path_tiles, num_classes):\n",
    "    \"\"\"This generator use a pandas DataFrame to read images (df.tile_name) from disk.\"\"\"\n",
    "    \n",
    "    # Number of images\n",
    "    N = df.shape[0]\n",
    "    \n",
    "    while True:\n",
    "        # Loop from 0 to N in batch_size increments\n",
    "        for start in range(0, N, batch_size):\n",
    "            \n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            # Find what is the ending of the TMP df, to avoid going over the index\n",
    "            end = min(start + batch_size, N)\n",
    "            df_tmp = df[start:end]\n",
    "            \n",
    "            # Get the URL's of tmp DF\n",
    "            ids_batch = df_tmp.tile_name\n",
    "            \n",
    "            # Run through each URL and download each image\n",
    "            for id in ids_batch:\n",
    "                \n",
    "                # Use the openCV library to read an image from a file\n",
    "                img = cv2.imread(os.path.join(path_tiles, id))\n",
    "                \n",
    "                # Create label for the current image\n",
    "                labelname=df_tmp['y'][df_tmp.tile_name == id].values[0]  \n",
    "                labelname=np.asscalar(labelname)\n",
    "                \n",
    "                # Append image to X_batch and label to y_batch\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(labelname)\n",
    "            \n",
    "            # Scale the x_batch to values between 0 and 1\n",
    "            x_batch = np.array(x_batch, np.float32) / 255\n",
    "            \n",
    "            # Turn y_batch into categorical\n",
    "            y_batch = utils.np_utils.to_categorical(y_batch, num_classes)\n",
    "            \n",
    "            # Yield x_batch and y_batch, which will return a generator function\n",
    "            yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we have the generator, here is how we can use fit_generator in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=batch_generator(df_train,\n",
    "                                              batch_size=batch_size,\n",
    "                                              path_tiles=path_tiles,\n",
    "                                              num_classes=num_classes),\n",
    "                    steps_per_epoch=len(df_train) // batch_size,\n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data/Image Augmentation - and why to use it.\n",
    "\n",
    "- Data/Image Augmentation is one of the best ways to improve the performance of a Deep Learning model, and to add variance to the training dataset\n",
    "- We want our input images to be representetive of different lighting, angles, positions and so on...\n",
    "\n",
    "**How do we do this in Keras?**  \n",
    "- Can use ImageDataGenerator\n",
    "- Write our own custom code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from \n",
    "train_data_gen "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
