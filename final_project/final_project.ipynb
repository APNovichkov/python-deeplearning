{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# Import standard libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import Keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "# from keras.layers.convolutional import Conv2D\n",
    "# from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Import sklearn packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Import other utils\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Classifying Fire Images with CNN+MLP Model\n",
    "## Andrey Novichkov - June 16, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the goal of this project?\n",
    "- I want to take in input images, some with fire, and some without, and build a Neural Net that will be able, with high accuracy, classify the images as having fire or without.\n",
    "\n",
    "## Inputs:\n",
    "- A folder with images that contain fire\n",
    "- A folder with images that do not contain fire\n",
    "- Link to input data -> https://github.com/cair/Fire-Detection-Image-Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go step by step:\n",
    "1. Import the data into a dataframe\n",
    "2. Split df into train and test\n",
    "3. Create a data generator that will generate x_batch and y_batch, where x_batch is the image converted into a numpy array, and y_batch, which are the categorical labels: **1 for fire, 0 for no fire**\n",
    "4. Define CNN+MLP model\n",
    "5. Compile the model\n",
    "6. Use fit_generator to train the model\n",
    "7. Evaluate the model\n",
    "8. Apply data augmentation and rebuild, retrain and re-evaluate model\n",
    "9. Apply hyperparameter optimization and rebuild, retrain and re-evaluate model\n",
    "10. Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "FIRE_IMAGE_DIR = 'fire_images'\n",
    "FIRE_IMAGE_CLASS = '1'\n",
    "\n",
    "NORMAL_IMAGE_DIR = 'normal_images'\n",
    "NORMAL_IMAGE_CLASS = '0'\n",
    "\n",
    "DF_COLS = ['folder', 'filename', 'label']\n",
    "\n",
    "REDUCED_IMAGE_SIZE = 1024\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data into dataframes\n",
    "fire_list = []\n",
    "normal_list = []\n",
    "\n",
    "for file in glob.glob(f'{FIRE_IMAGE_DIR}/*'):\n",
    "    fire_list.append([FIRE_IMAGE_DIR, os.path.basename(file), FIRE_IMAGE_CLASS])\n",
    "\n",
    "for file in glob.glob(f'{NORMAL_IMAGE_DIR}/*'):\n",
    "    normal_list.append([NORMAL_IMAGE_DIR, os.path.basename(file), NORMAL_IMAGE_CLASS])\n",
    "    \n",
    "fire_df = pd.DataFrame(fire_list, columns=DF_COLS)\n",
    "normal_df = pd.DataFrame(normal_list, columns=DF_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>folder</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fire_images</td>\n",
       "      <td>dsc_01001.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fire_images</td>\n",
       "      <td>burning-charcoal-briquettes.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       folder                         filename label\n",
       "0      0  fire_images                    dsc_01001.jpg     1\n",
       "1      1  fire_images  burning-charcoal-briquettes.jpg     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the two DF's\n",
    "df = pd.concat([fire_df, normal_df]).reset_index()\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataframe into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df into train and test\n",
    "df_train, df_test = train_test_split(df, test_size=.2, random_state=0)\n",
    "df_train = df_train.reset_index().drop(['level_0', 'index'], axis=1)\n",
    "df_test = df_test.reset_index().drop(['level_0', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data generator\n",
    "def data_generator(df, batch_size):\n",
    "    while True:\n",
    "        x_batch = np.zeros((batch_size, REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE, 3))\n",
    "        y_batch = np.zeros((batch_size, 1))\n",
    "        global_i = 0\n",
    "\n",
    "        for batch_index in range(len(df)//batch_size):\n",
    "            start_batch_index = batch_index*batch_size\n",
    "            end_batch_index = (batch_index+1)*batch_size\n",
    "            local_i = 0\n",
    "\n",
    "            for filename, label in zip(df['filename'][start_batch_index:end_batch_index], df['label'][start_batch_index:end_batch_index]):\n",
    "                folder = df['folder'][global_i]\n",
    "                img = Image.open(os.path.join(folder, filename))\n",
    "                img = img.resize((REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE))\n",
    "                x_batch[local_i] = img_to_array(img)\n",
    "                y_batch[local_i] = label\n",
    "                global_i += 1\n",
    "                local_i += 1\n",
    "        \n",
    "            yield x_batch, np_utils.to_categorical(y_batch, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN+MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN+MLP model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE, 3)))\n",
    "model.add(Conv2D(4, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Conv2D(4, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Conv2D(4, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 1022, 1022, 4)     112       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1020, 1020, 4)     148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 510, 510, 4)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 510, 510, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 508, 508, 4)       148       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 506, 506, 4)       148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 253, 253, 4)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 253, 253, 4)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256036)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                8193184   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 8,193,806\n",
      "Trainable params: 8,193,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model\n",
    "- Passing in the data generator function as the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 273s 27s/step - loss: 2.5969 - acc: 0.8380\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 237s 24s/step - loss: 2.5969 - acc: 0.8380\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 534s 53s/step - loss: 2.5969 - acc: 0.8380\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 301s 30s/step - loss: 2.5969 - acc: 0.8380\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 276s 28s/step - loss: 2.5969 - acc: 0.8380\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "history = model.fit_generator(data_generator(df_train, batch_size), steps_per_epoch=len(df_train)//batch_size, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like model stopped learning after some time, but still pretty good accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's add Data Augmentation to the model\n",
    "- Essentially we create new images that are rotated, flipped, etc... and feed them to the same model by using ImageDataGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y_from_df(df):\n",
    "    x_batch = np.zeros((len(df), REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE, 3))\n",
    "    y_batch = np.zeros((len(df), 1))\n",
    "    global_i = 0\n",
    "\n",
    "    for index in range(len(df)):\n",
    "        start_batch_index = index\n",
    "        end_batch_index = index + 1\n",
    "\n",
    "        for filename, label in zip(df['filename'][start_batch_index:end_batch_index], df['label'][start_batch_index:end_batch_index]):\n",
    "            folder = df['folder'][index]\n",
    "            img = Image.open(os.path.join(folder, filename))\n",
    "            img = img.resize((REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE))\n",
    "            x_batch[index] = img_to_array(img)\n",
    "            y_batch[index] = label\n",
    "\n",
    "\n",
    "    return x_batch, np_utils.to_categorical(y_batch, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "x_train, y_train = get_x_y_from_df(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "11/10 [===============================] - 260s 24s/step - loss: 2.6888 - acc: 0.8323\n",
      "Epoch 2/2\n",
      "11/10 [===============================] - 227s 21s/step - loss: 2.6320 - acc: 0.8358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14096f8d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=50),\n",
    "                    steps_per_epoch=len(x_train) / 50, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Really similar accuracy as before, can't say if data augmentation improved the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add another Dense layer to MLP, change some activation functions to tanh, keep everything else the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, lets try to otpimize parameters\n",
    "# Define CNN+MLP model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE, 3)))\n",
    "model.add(Conv2D(4, kernel_size=(3,3), activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Conv2D(4, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Conv2D(4, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 1022, 1022, 4)     112       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 1020, 1020, 4)     148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 510, 510, 4)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 510, 510, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 508, 508, 4)       148       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 506, 506, 4)       148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 253, 253, 4)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 253, 253, 4)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 256036)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                8193184   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 8,195,982\n",
      "Trainable params: 8,195,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 295s 30s/step - loss: 2.4537 - acc: 0.7970\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 261s 26s/step - loss: 2.5969 - acc: 0.8380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10bd848d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "model.fit_generator(data_generator(df_train, batch_size), steps_per_epoch=len(df_train)//batch_size, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, very similar accuracy... let's try some more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change optimizer to adadelta (after seeing some examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 403s 40s/step - loss: 2.4238 - acc: 0.8310\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 435s 43s/step - loss: 2.5969 - acc: 0.8380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1400f1450>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lastly, lets try to otpimize parameters\n",
    "# Define CNN+MLP model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE, 3)))\n",
    "model.add(Conv2D(4, kernel_size=(3,3), activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Conv2D(4, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Conv2D(4, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 50\n",
    "model.fit_generator(data_generator(df_train, batch_size), steps_per_epoch=len(df_train)//batch_size, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, very similar accuracy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do a model.predict() on this model and compute predicted accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = get_x_y_from_df(df_test)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.81\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy score is: {round(accuracy_score(y_test, y_pred), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "- Overall, I am pretty happy with my final NN model and its accuracy.\n",
    "- Was able to use generators to fit the model\n",
    "- Successfuly attempted to use data augmentation to improve the model, but no significant increase\n",
    "- Was able to make predictions using the model\n",
    "\n",
    "## Possible improvements:\n",
    "- In general, the latest models seemed to learn over epochs, there is just a limit on how many epochs I can run, as my computer does not have a lot of resources\n",
    "- Batch size could also be smaller, but will run for a really long time, and time is a constraint\n",
    "- Training these models on AWS could be a good idea, especially CNN's when processing relatively big images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
