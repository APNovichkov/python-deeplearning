{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# Import standard libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import Keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "# from keras.layers.convolutional import Conv2D\n",
    "# from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Import sklearn packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import other utils\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Classifying Fire Images with CNN+MLP Model\n",
    "## Andrey Novichkov - June 16, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the goal of this project?\n",
    "- I want to take in input images, some with fire, and some without, and build a Neural Net that will be able, with high accuracy, classify the images as having fire or without.\n",
    "\n",
    "## Inputs:\n",
    "- A folder with images that contain fire\n",
    "- A folder with images that do not contain fire\n",
    "- Link to input data -> https://github.com/cair/Fire-Detection-Image-Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go step by step:\n",
    "1. Import the data into a dataframe\n",
    "2. Split df into train and test\n",
    "3. Create a data generator that will generate x_batch and y_batch, where x_batch is the image converted into a numpy array, and y_batch, which are the categorical labels: **1 for fire, 0 for no fire**\n",
    "4. Define CNN+MLP model\n",
    "5. Compile the model\n",
    "6. Use fit_generator to train the model\n",
    "7. Evaluate the model\n",
    "8. Apply data augmentation and rebuild, retrain and re-evaluate model\n",
    "9. Apply hyperparameter optimization and rebuild, retrain and re-evaluate model\n",
    "10. Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "FIRE_IMAGE_DIR = 'fire_images'\n",
    "FIRE_IMAGE_CLASS = '1'\n",
    "\n",
    "NORMAL_IMAGE_DIR = 'normal_images'\n",
    "NORMAL_IMAGE_CLASS = '0'\n",
    "\n",
    "DF_COLS = ['folder', 'filename', 'label']\n",
    "\n",
    "REDUCED_IMAGE_SIZE = 1024\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data into dataframes\n",
    "fire_list = []\n",
    "normal_list = []\n",
    "\n",
    "for file in glob.glob(f'{FIRE_IMAGE_DIR}/*'):\n",
    "    fire_list.append([FIRE_IMAGE_DIR, os.path.basename(file), FIRE_IMAGE_CLASS])\n",
    "\n",
    "for file in glob.glob(f'{NORMAL_IMAGE_DIR}/*'):\n",
    "    normal_list.append([NORMAL_IMAGE_DIR, os.path.basename(file), NORMAL_IMAGE_CLASS])\n",
    "    \n",
    "fire_df = pd.DataFrame(fire_list, columns=DF_COLS)\n",
    "normal_df = pd.DataFrame(normal_list, columns=DF_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>folder</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fire_images</td>\n",
       "      <td>dsc_01001.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fire_images</td>\n",
       "      <td>burning-charcoal-briquettes.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       folder                         filename label\n",
       "0      0  fire_images                    dsc_01001.jpg     1\n",
       "1      1  fire_images  burning-charcoal-briquettes.jpg     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the two DF's\n",
    "df = pd.concat([fire_df, normal_df]).reset_index()\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df into train and test\n",
    "df_train, df_test = train_test_split(df, test_size=.2, random_state=0)\n",
    "df_train = df_train.reset_index().drop(['level_0', 'index'], axis=1)\n",
    "df_test = df_test.reset_index().drop(['level_0', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data generator\n",
    "def data_generator(df, batch_size):\n",
    "    while True:\n",
    "        x_batch = np.zeros((batch_size, REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE, 3))\n",
    "        y_batch = np.zeros((batch_size, 1))\n",
    "        global_i = 0\n",
    "\n",
    "        for batch_index in range(len(df)//batch_size):\n",
    "            start_batch_index = batch_index*batch_size\n",
    "            end_batch_index = (batch_index+1)*batch_size\n",
    "            local_i = 0\n",
    "\n",
    "            for filename, label in zip(df['filename'][start_batch_index:end_batch_index], df['label'][start_batch_index:end_batch_index]):\n",
    "                folder = df['folder'][global_i]\n",
    "                img = Image.open(os.path.join(folder, filename))\n",
    "                img = img.resize((REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE))\n",
    "                x_batch[local_i] = img_to_array(img)\n",
    "                y_batch[local_i] = label\n",
    "                global_i += 1\n",
    "                local_i += 1\n",
    "        \n",
    "            yield x_batch, np_utils.to_categorical(y_batch, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN+MLP model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE, 3)))\n",
    "model.add(Conv2D(4, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Conv2D(4, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Conv2D(4, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 1022, 1022, 4)     112       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1020, 1020, 4)     148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 510, 510, 4)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 510, 510, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 508, 508, 4)       148       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 506, 506, 4)       148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 253, 253, 4)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 253, 253, 4)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256036)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                8193184   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 8,193,806\n",
      "Trainable params: 8,193,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 273s 27s/step - loss: 2.5969 - acc: 0.8380\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 237s 24s/step - loss: 2.5969 - acc: 0.8380\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 534s 53s/step - loss: 2.5969 - acc: 0.8380\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 301s 30s/step - loss: 2.5969 - acc: 0.8380\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 276s 28s/step - loss: 2.5969 - acc: 0.8380\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "history = model.fit_generator(data_generator(df_train, batch_size), steps_per_epoch=len(df_train)//batch_size, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like model stopped learning after some time, still a good model tho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data generator\n",
    "def data_generator(df, batch_size):\n",
    "    while True:\n",
    "        x_batch = np.zeros((batch_size, REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE, 3))\n",
    "        y_batch = np.zeros((batch_size, 1))\n",
    "        global_i = 0\n",
    "\n",
    "        for batch_index in range(len(df)//batch_size):\n",
    "            start_batch_index = batch_index*batch_size\n",
    "            end_batch_index = (batch_index+1)*batch_size\n",
    "            local_i = 0\n",
    "\n",
    "            for filename, label in zip(df['filename'][start_batch_index:end_batch_index], df['label'][start_batch_index:end_batch_index]):\n",
    "                folder = df['folder'][global_i]\n",
    "                img = Image.open(os.path.join(folder, filename))\n",
    "                img = img.resize((REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE))\n",
    "                x_batch[local_i] = img_to_array(img)\n",
    "                y_batch[local_i] = label\n",
    "                global_i += 1\n",
    "                local_i += 1\n",
    "        \n",
    "            yield datagenx_batch, np_utils.to_categorical(y_batch, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y_train_from_df(df):\n",
    "     x_batch = np.zeros((batch_size, REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE, 3))\n",
    "        y_batch = np.zeros((batch_size, 1))\n",
    "        global_i = 0\n",
    "\n",
    "        for index in range(len(df)):\n",
    "            start_batch_index = index\n",
    "            end_batch_index = index + 1\n",
    "            local_i = 0\n",
    "\n",
    "            for filename, label in zip(df['filename'][start_batch_index:end_batch_index], df['label'][start_batch_index:end_batch_index]):\n",
    "                folder = df['folder'][global_i]\n",
    "                img = Image.open(os.path.join(folder, filename))\n",
    "                img = img.resize((REDUCED_IMAGE_SIZE, REDUCED_IMAGE_SIZE))\n",
    "                x_batch[local_i] = img_to_array(img)\n",
    "                y_batch[local_i] = label\n",
    "                global_i += 1\n",
    "                local_i += 1\n",
    "        \n",
    "            yield datagenx_batch, np_utils.to_categorical(y_batch, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
